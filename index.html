<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Tahereh Toosi - Academic Website</title>
    <style>
        /* 
        COLOR ALTERNATIVES - Uncomment to test:
        
        Name Color Options:
        --name-color: #7c3aed;         Current: Modern purple/violet
        --name-color: #8b5cf6;         Lighter purple
        --name-color: #6366f1;         Indigo
        --name-color: #059669;         Emerald green
        --name-color: #0d9488;         Teal (matches section color)
        --name-color: #dc2626;         Deep red
        --name-color: #ea580c;         Orange
        --name-color: #9333ea;         Deep purple
        
        Font Alternatives - Replace in body and h1,h2,h3:
        font-family: 'Inter', -apple-system, BlinkMacSystemFont, sans-serif;  Modern, clean
        font-family: 'Poppins', sans-serif;  Geometric, friendly
        font-family: 'Playfair Display', serif;  Elegant serif for headings
        font-family: 'Lora', serif;  Readable serif
        font-family: 'Source Sans Pro', sans-serif;  Professional
        font-family: 'Roboto', sans-serif;  Google's clean font
        font-family: 'Work Sans', sans-serif;  Modern, versatile
        */
        
        :root {
            /* Light theme (default) */
            --name-color: #fc5203;         /* Warm orange-red - vibrant and modern */
            --section-title-color: #006699; /* Teal-blue - back to original greenish-blue */
            --text-primary: #1e293b;        /* Slate-800 - richer dark */
            --text-secondary: #475569;      /* Slate-600 - softer medium gray */
            --text-tertiary: #64748b;       /* Slate-500 - lighter gray */
            --accent-color: #0088aa;        /* Teal-blue accent - slightly brighter */
            --border-color: #e2e8f0;        /* Slate-200 - soft borders */
            --bg-subtle: #f8fafc;          /* Slate-50 - very light background */
            --bg-primary: #ffffff;         /* White background */
            --bg-secondary: #f9f9f9;       /* Light gray background */
            --text-body: #333333;          /* Dark text */
            --update-text: #333333;         /* Update text color */
            --update-details: #666666;      /* Update details color */
            /* Mobile layout variables */
            --mobile-name-top-offset: 45px;  /* Adjust vertical position of name relative to image */
            --mobile-content-gap: 60px;   /* Gap between image+name row and description text below */
        }
        
        /* Dark theme */
        @media (prefers-color-scheme: dark) {
            :root {
                --name-color: #ff6b3d;         /* Slightly brighter orange-red for dark theme */
                --section-title-color: #4dd0e1; /* Lighter teal-blue for dark theme */
                --text-primary: #e2e8f0;        /* Light slate for dark theme */
                --text-secondary: #cbd5e1;      /* Lighter gray */
                --text-tertiary: #94a3b8;       /* Medium gray */
                --accent-color: #5dd3e8;        /* Brighter teal accent */
                --border-color: #334155;        /* Dark slate borders */
                --bg-subtle: #1e293b;          /* Dark slate background */
                --bg-primary: #0f172a;         /* Very dark blue background */
                --bg-secondary: #1e293b;       /* Dark slate for cards */
                --text-body: #e2e8f0;          /* Light text */
                --update-text: #e2e8f0;        /* Light update text */
                --update-details: #94a3b8;     /* Lighter update details */
            }
        }
        
        body {
            font-family: 'Open Sans', Verdana, sans-serif;
            line-height: 1.6;
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
            color: var(--text-body);
            background-color: var(--bg-primary);
            transition: background-color 0.3s ease, color 0.3s ease;
        }
        header {
            display: flex;
            align-items: center;
            margin-bottom: 30px;
        }
        .header-top {
            display: contents;
        }
        .profile-img {
            width: 200px;
            border-radius: 50%;
            margin-right: 30px;
            box-shadow: 0 4px 8px rgba(0,0,0,0.2);
            flex-shrink: 0;
        }
        .header-content {
            flex: 1;
        }
        h1, h2, h3 {
            font-family: 'Montserrat', Arial, sans-serif;
            color: var(--section-title-color);
            font-weight: 600;
        }
        h2 {
            margin-top: 40px;
            margin-bottom: 20px;
            padding-bottom: 8px;
            border-bottom: 2px solid var(--border-color);
            position: relative;
        }
        h2::after {
            content: '';
            position: absolute;
            bottom: -2px;
            left: 0;
            width: 60px;
            height: 2px;
            background: linear-gradient(90deg, var(--section-title-color), transparent);
        }
        h1 {
            margin-bottom: 5px;
            color: var(--name-color);
        }
        .header-top h1 {
            cursor: pointer;
            transition: opacity 0.3s;
        }
        .header-top h1:hover {
            opacity: 0.8;
        }
        .header-top h1 a {
            color: inherit;
            text-decoration: none;
        }
        /* Fixed name on left when scrolled (desktop only) */
        .fixed-name {
            display: none;
        }
        @media (min-width: 769px) {
            .fixed-name {
                position: fixed;
                left: 20px;
                top: 50%;
                transform: translateY(-50%);
                z-index: 1000;
                background: linear-gradient(135deg, var(--bg-primary) 0%, var(--bg-subtle) 100%);
                backdrop-filter: blur(10px);
                padding: 15px 20px;
                border-radius: 12px;
                box-shadow: 0 4px 16px rgba(0,0,0,0.08), 0 2px 8px rgba(0,0,0,0.04);
                border: 1px solid var(--border-color);
                cursor: pointer;
                transition: all 0.3s cubic-bezier(0.4, 0, 0.2, 1);
            }
            @media (prefers-color-scheme: dark) {
                .fixed-name {
                    box-shadow: 0 4px 16px rgba(0,0,0,0.4), 0 2px 8px rgba(0,0,0,0.3);
                }
            }
            .fixed-name:hover {
                box-shadow: 0 8px 24px rgba(0, 102, 153, 0.12), 0 4px 12px rgba(0,0,0,0.08);
                transform: translateY(-50%) scale(1.02);
            }
            .fixed-name h1 {
                margin: 0;
                font-size: 0.98em;
                color: rgba(102, 102, 102, 0.7);
            }
            @media (prefers-color-scheme: dark) {
                .fixed-name h1 {
                    color: rgba(200, 200, 200, 0.9);
                }
            }
            .fixed-name a {
                color: inherit;
                text-decoration: none;
            }
        }
        .affiliation {
            color: var(--text-tertiary);
            font-size: 1em;
            margin-bottom: 15px;
            line-height: 1.5;
        }
        .affiliation-line {
            display: block;
        }
        .research-description {
            color: var(--text-body);
            margin-top: 10px;
            margin-bottom: 15px;
            line-height: 1.6;
        }
        .support-section {
            color: var(--text-tertiary);
            font-size: 0.95em;
            margin-top: 15px;
            line-height: 1.5;
            font-style: italic;
        }
        .projects {
            margin-top: 40px;
        }
        .projects h2 {
            color: var(--section-title-color);
        }
        .project {
            margin-bottom: 30px;
            padding: 24px;
            border-radius: 16px;
            background: linear-gradient(135deg, var(--bg-primary) 0%, var(--bg-subtle) 100%);
            box-shadow: 0 1px 3px rgba(0,0,0,0.08), 0 1px 2px rgba(0,0,0,0.06);
            border: 1px solid var(--border-color);
            transition: all 0.3s cubic-bezier(0.4, 0, 0.2, 1);
        }
        @media (prefers-color-scheme: dark) {
            .project {
                box-shadow: 0 1px 3px rgba(0,0,0,0.3), 0 1px 2px rgba(0,0,0,0.2);
            }
        }
        .project:hover {
            box-shadow: 0 10px 25px rgba(0, 102, 153, 0.1), 0 4px 10px rgba(0,0,0,0.08);
            transform: translateY(-3px);
            border-color: rgba(0, 102, 153, 0.2);
        }
        .project h3 {
            margin-top: 0;
        }
        .project h4 {
            color: var(--text-tertiary);
            font-family: 'Open Sans', Verdana, sans-serif;
            font-size: 1.1em;
            margin: 10px 0;
            font-style: italic;
        }
        .project .tags {
            display: flex;
            gap: 10px;
            margin: 15px 0 0 0;
        }
        .project .tag {
            padding: 3px 6px;
            border-radius: 4px;
            font-size: 0.7em;
            font-family: 'Open Sans', Verdana, sans-serif;
            font-weight: 500;
        }
        .project .tag.neuroscience {
            background-color: #10b981; /* Emerald */
            color: #ffffff;
        }
        .project .tag.ai {
            background-color: #FDD7E4; /* Pale pink */
            color: #333333;
        }
        .project a {
            color: #9ca3af;
            text-decoration: underline;
            display: inline-block;
            transition: all 0.2s ease;
        }
        .project a:hover {
            color: #6b7280;
            text-decoration: underline;
            transform: translateY(-2px);
        }
        .project .gif-container {
            display: flex;
            gap: 20px;
            margin: 15px 0;
        }
        .project img {
            width: 200px;
            height: auto;
            border-radius: 8px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.2);
        }
        .publications {
            margin-top: 60px;
            padding-top: 20px;
        }
        .talks {
            margin-top: 60px;
            padding-top: 20px;
        }
        .publication {
            margin-bottom: 24px;
            border-left: 3px solid var(--section-title-color);
            padding-left: 18px;
            padding-top: 6px;
            padding-bottom: 6px;
            background: linear-gradient(to right, rgba(0, 102, 153, 0.02), transparent);
            border-radius: 0 4px 4px 0;
        }
        .publication:has(.title a) {
            transition: all 0.3s cubic-bezier(0.4, 0, 0.2, 1);
        }
        .publication:has(.title a):hover {
            transform: translateY(-3px);
            box-shadow: 0 10px 25px rgba(0, 102, 153, 0.1), 0 4px 10px rgba(0,0,0,0.08);
            border-left-color: var(--accent-color);
            border-left-width: 4px;
            padding-left: 22px;
            background: linear-gradient(to right, rgba(0, 102, 153, 0.05), transparent);
        }
        .publication p {
            margin: 5px 0;
        }
        .publication .title {
            font-weight: 600;
            font-size: 1.05em;
            color: var(--text-primary);
            margin-bottom: 4px;
        }
        .publication .authors {
            font-style: italic;
            color: var(--text-secondary);
            margin-bottom: 4px;
        }
        .publication .venue {
            color: var(--text-tertiary);
            font-size: 0.95em;
        }
        .talks .publication .title {
            font-weight: 600;
            font-size: 1.05em;
            color: var(--text-primary);
            margin-bottom: 6px;
        }
        .talks .publication .venue {
            font-style: italic;
            color: var(--text-tertiary);
            font-size: 0.95em;
        }
        .publications h2 {
            color: var(--section-title-color);
        }
        .nav {
            display: flex;
            justify-content: center;
            margin: 30px 0;
            gap: 20px;
        }
        .nav a {
            padding: 10px 20px;
            background-color: var(--bg-subtle);
            color: var(--section-title-color);
            text-decoration: none;
            border-radius: 4px;
            transition: all 0.3s;
            border: 1px solid var(--border-color);
        }
        .nav a:hover, .nav a.active {
            background-color: var(--bg-secondary);
            border-color: var(--accent-color);
        }
        html {
            scroll-behavior: smooth;
        }
        section {
            scroll-margin-top: 20px;
        }
        .social-icons {
            display: flex;
            margin-top: 15px;
            gap: 15px;
        }
        .social-icon {
            width: 24px;
            height: 24px;
        }
        .social-icon svg {
            width: 100%;
            height: 100%;
            fill: var(--section-title-color);
            transition: fill 0.3s;
        }
        .social-icon:hover svg {
            fill: var(--section-title-color);
        }
        .publication .title a {
            color: #5b8a9f !important;
            text-decoration: underline;
            transition: all 0.2s ease;
            display: inline-block;
        }
        .publication .title a:hover {
            color: #4a7a8f !important;
            text-decoration: underline;
            text-decoration-thickness: 2px;
            text-underline-offset: 3px;
            transform: translateY(-2px);
        }
        .recent-updates {
            margin-top: 40px;
            margin-bottom: 40px;
        }
        .recent-updates h2 {
            color: var(--section-title-color);
            margin-bottom: 20px;
        }
        .update-item {
            margin-bottom: 15px;
            padding: 10px 0;
            border-bottom: 1px solid var(--border-color);
        }
        .update-item:last-child {
            border-bottom: none;
        }
        .update-date {
            color: #fc5203;
            font-weight: bold;
            font-size: 0.9em;
        }
        .update-text {
            color: var(--update-text);
            margin-top: 5px;
        }
        .update-details {
            color: var(--update-details);
            font-size: 0.9em;
            margin-top: 3px;
            font-style: italic;
        }
        
        /* Mobile responsive styles */
        @media (max-width: 768px) {
            header {
                flex-direction: column;
                align-items: flex-start;
                position: relative;
            }
            .profile-img {
                width: 120px;
                height: 120px;
                margin-right: 15px;
                margin-bottom: 0;
                position: absolute;
                top: 0;
                left: 0;
                flex-shrink: 0;
            }
            .header-content {
                width: 100%;
                padding-left: 135px;
                min-height: 120px;
            }
            .header-top {
                display: flex !important;
                flex-direction: row;
                align-items: center;
                gap: 0;
                width: calc(100% - 135px);
                margin-bottom: 0;
                margin-top: var(--mobile-name-top-offset);
            }
            .header-top h1 {
                margin: 0;
                flex: 1;
                font-size: 1.5em;
            }
            /* Make description content start from left edge, below image+name row */
            .header-content .affiliation,
            .header-content .research-description,
            .header-content .support-section,
            .header-content .social-icons {
                margin-left: -135px;
                padding-left: 0;
                width: 100%;
            }
            /* Push all description content down below the image+name row */
            .header-content .affiliation {
                margin-top: var(--mobile-content-gap);
            }
        }
    </style>
</head>
<body>
    <!-- Fixed name that appears when scrolled (desktop only) -->
    <div class="fixed-name" id="fixedName">
        <h1><a href="#" onclick="window.scrollTo({top: 0, behavior: 'smooth'}); return false;">Tahereh Toosi</a></h1>
    </div>
    <header>
        <img src="assets/profile_400x400-.png" alt="Tahereh Toosi" class="profile-img">
        <div class="header-content">
            <div class="header-top">
                <h1><a href="#" onclick="window.scrollTo({top: 0, behavior: 'smooth'}); return false;" style="color: inherit; text-decoration: none;">Tahereh Toosi, PhD</a></h1>
            </div>
            <div class="affiliation">
                <span class="affiliation-line">Associate Research Scientist</span>
                <span class="affiliation-line"><a href="https://ctn.zuckermaninstitute.columbia.edu/" target="_blank" style="color: #9ca3af;">Center for Theoretical Neuroscience</a></span>
                <span class="affiliation-line">Columbia University</span>
            </div>
            <p class="research-description">
                My research bridges computational neuroscience and AI, focusing on building intrinsically aligned models of visual perception. My research leverages AI tools and biological constraints to understand core intelligence.
            </p>
            <div class="support-section">
                Supported by an <a href="https://reporter.nih.gov/project-details/1K99EY035357-01" target="_blank" style="color: #9ca3af;">NIH K99/R00</a> award and Neural Mechanisms grant from <a href="https://arni-institute.org/research/" target="_blank" style="color: #9ca3af;">Institute for Artificial and Natural Intelligence (ARNI)/NSF</a>.
            </div>
            <div class="social-icons">
                <a href="https://github.com/toosi" target="_blank" class="social-icon" title="GitHub">
                    <img src="https://img.icons8.com/?size=100&id=akG4VRhAoSii&format=png&color=000000" alt="GitHub" style="width: 24px; height: 24px;">
                </a>
                <a href="https://twitter.com/taherehtoosi" target="_blank" class="social-icon" title="Twitter">
                    <img src="https://img.icons8.com/?size=100&id=0Yx1qZsfjtk0&format=png&color=000000" alt="Twitter" style="width: 24px; height: 24px;">
                </a>
                <a href="https://bsky.app/profile/taherehtoosi.bsky.social" target="_blank" class="social-icon" title="Bluesky">
                    <img src="https://img.icons8.com/?size=100&id=3ovMFy5JDSWq&format=png&color=000000" alt="Bluesky" style="width: 24px; height: 24px;">
                </a>
                <a href="https://scholar.google.com/citations?user=fDjSvTsAAAAJ&hl=en" target="_blank" class="social-icon" title="Google Scholar">
                    <img src="https://img.icons8.com/?size=100&id=drPiDBy9kkJ3&format=png&color=000000" alt="Google Scholar" style="width: 24px; height: 24px;">
                </a>
                <a href="https://www.linkedin.com/in/tahereh-toosi-45b99014/" target="_blank" class="social-icon" title="LinkedIn">
                    <img src="https://img.icons8.com/?size=100&id=13930&format=png&color=000000" alt="LinkedIn" style="width: 24px; height: 24px;">
                </a>
                <!-- <a href="mailto:tahereh.toosi@columbia.edu" class="social-icon" title="Email">
                    <svg role="img" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M24 5.457v13.909c0 .904-.732 1.636-1.636 1.636h-3.819V11.73L12 16.64l-6.545-4.91v9.273H1.636A1.636 1.636 0 0 1 0 19.366V5.457c0-2.023 2.309-3.178 3.927-1.964L5.455 4.64 12 9.548l6.545-4.91 1.528-1.145C21.69 2.28 24 3.434 24 5.457z"/></svg>
                </a> -->
                <!-- <a href="assets/Tahereh_CV_2025_norefs.pdf" target="_blank" class="social-icon" title="CV">
                    <img src="assets/icons/CV.png" alt="CV" style="width: 24px; height: 24px;">
                </a> -->
            </div>
        </div>
    </header>

    <nav class="nav">
        <a href="#research-lines">Research Lines</a>
        <a href="#publications">Publications</a>
        <a href="#talks">Talks</a>
    </nav>

    <section id="projects" class="projects">
        <div class="recent-updates">
            <h2>Recent Updates</h2>
            
            <div class="update-item">
                <div class="update-date">October 2025</div>
                <div class="update-text">Preprints released:</div>
                <div class="update-details"><a href="https://www.biorxiv.org/content/10.1101/2025.10.21.683535v2" target="_blank" style="color: #006699; text-decoration: underline;">"Generative inference unifies feedback processing for learning and perception in natural and artificial vision"</a></div>
                <div class="update-details">Toosi, T., & Miller, K. D.</div>
                <div class="update-details" style="margin-top: 8px;">
                    <a href="https://www.biorxiv.org/content/10.1101/2025.10.21.683535v2" target="_blank" style="color: #006699; text-decoration: underline; margin-right: 15px;">Paper</a>
                    <a href="https://x.com/taherehtoosi/status/1981716460549382231" target="_blank" style="color: #006699; text-decoration: underline; margin-right: 15px;">Summary</a>
                    <a href="https://huggingface.co/spaces/ttoosi/GenerativeInferenceDemo" target="_blank" style="color: #006699; text-decoration: underline; margin-right: 15px;">Demo</a>
                    <a href="https://github.com/toosi/Generative_Inference_Perception" target="_blank" style="color: #006699; text-decoration: underline;">Code</a>
                </div>
                <div class="update-details" style="margin-top: 15px;"><a href="https://www.biorxiv.org/content/10.1101/2025.10.29.685363v1.abstract" target="_blank" style="color: #006699; text-decoration: underline;">"Natural Scene Coding Consistency in Genetically-Defined Cell Populations"</a></div>
                <div class="update-details">Toosi, T., & Miller, K. D.</div>
            </div>
            
            <div class="update-item">
                <div class="update-date">September 2025</div>
                <div class="update-text">Papers accepted at NeurIPS workshops:</div>
                <div class="update-details">"Unifying Gestalt Principles Through Inference-Time Prior Integration"</div>
                <div class="update-details">Toosi, T., & Miller, K. D. — Interpreting Cognition in Deep Learning Models Workshop</div>
                <div class="update-details" style="margin-top: 10px;"><a href="#" target="_blank" style="color: #006699; text-decoration: underline;">"Interpretability at the Network Level: Prior-Guided Drift Diffusion for Neural Circuit Analysis"</a></div>
                <div class="update-details">Toosi, T. — Mechanistic Interpretability Workshop</div>
            </div>
            
            <div class="update-item">
                <div class="update-date">July 2025</div>
                <div class="update-text">Awarded a grant from <a href="https://arni-institute.org/" target="_blank" style="color: #9ca3af;">Institute for Artificial and Natural Intelligence (ARNI)</a></div>
                <div class="update-details">"Modular Computations in AI and Neuroscience: Principles and Applications"</div>
                <div class="update-details">Toosi, T., Miller, K. D., & Abbott, L. F.</div>
            </div>
        </div>
        
        <h2 id="research-lines">Research Lines</h2>
        <div class="project">
            <h3><a href="research/generative-inference.html">Neural basis of perception</a></h3>
            <h4>Understanding how neural networks give rise to perceptual grouping, illusory percepts, and imagination </h4>
            <div class="gif-container">
                <img src="assets/gifs/FaceVase1_movie.gif" alt="Face-Vase Illusion Transformation 1">
                <img src="assets/gifs/FaceVase2_movie.gif" alt="Face-Vase Illusion Transformation 2">
            </div>
            <div class="gif-container">
                <img src="project_generative_inference/kanizsa_demo.gif" alt="Kanitza">
                <img src="project_generative_inference/neon_demo.gif" alt="Neon">
            </div>
            <div class="gif-container">

                <img src="project_generative_inference/gestalt_demo.gif" alt="Gestalt" style="width: 410px;">
            </div>
            <div class="gif-container">
                <img src="project_generative_inference/imagination_demo_combined_slow.gif" alt="Imagination" style="width: 410px;">
            </div>
            <div class="tags">
                <span class="tag neuroscience">Neuroscience</span>
                <span class="tag ai">AI</span>
            </div>
        </div>

        <div class="project">
            <h3><a href="research/data-driven-discovery.html">Data-Driven Discovery of Computational Principles in Naturalistic Brain and Behavior</a></h3>
            <img src="assets/Celltype_plan_allen.png" alt="Cell type plan Allen" style="width:100%;max-width:800px;display:block;margin:20px auto 0 auto;border-radius:8px;box-shadow:0 2px 8px rgba(0,0,0,0.3);" />
            <div style="text-align:center;color:#666666;font-size:0.9em;font-style:italic;margin-top:-10px;margin-bottom:15px;">Data: <a href="https://observatory.brain-map.org/visualcoding/" target="_blank" style="color:#006699;text-decoration:underline;">Allen Brain Observatory</a></div>
            <div class="tags">
                <span class="tag neuroscience">Neuroscience</span>
                <span class="tag ai">AI</span>
            </div>
        </div>

        <!-- <div class="project">
            <h3><a href="research/mechanistic_interpretability.html">Interpretability at the Network Level: Prior-Guided Drift Diffusion for Neural Circuit Analysis</a></h3>
            <h4>Understanding what concepts networks have learned by treating them as generative models to probe their learned statistical priors</h4>
            <div class="gif-container">
                <img src="project_generative_inference/imagination_demo_combined_slow.gif" alt="PGDD Network Interpretability" style="width: 410px;">
            </div>
            <div class="tags">
                <span class="tag neuroscience">Neuroscience</span>
                <span class="tag ai">AI</span>
            </div>
        </div> -->
        
        <div class="project">
            <h3><a href="research/feedback-feedforward.html">Bio-plausible learning algorithms</a></h3>
            <h4>Realisitc alternatives to backpropagation of errors</h4>
            
            <img src="assets/gifs/tweets_FFA.gif" alt="Feedback-Feedforward Alignment GIF" style="width:100%;max-width:600px;height:auto;margin:10px 0;" />
            <div class="tags">
                <span class="tag neuroscience">Neuroscience</span>
                <span class="tag ai">AI</span>
            </div>
        </div>
        
        <div class="project">
            <h3><a href="research/straightened-representations.html">Emergence of temporally predictive representations in robust neural networks</a></h3>
            <h4>Robustness to input noise leads to emergent temporal predictability in neural representations</h4>
            <!-- <p>In this project, we explore how robust training techniques foster the emergence of straightened feature representations in feedforward neural networks when processing natural movie sequences. By leveraging adversarial robustness and random smoothing, our models exhibit a notable decrease in curvature within their latent spaces—allowing for linear interpolation of temporal frames and reliable frame reconstruction. These straightened representations align with perceptual phenomena observed in human vision and demonstrate improved predictivity of neural activity in primary visual cortex (V1). Our results suggest that noise robustness can serve as a parsimonious and biologically plausible mechanism for generating temporal predictability in visual representations.</p> -->
            <img src="assets/gifs/temporal.png" alt="Temporal Representations Preview" style="width:100%;max-width:800px;display:block;margin:20px auto 0 auto;border-radius:8px;box-shadow:0 2px 8px rgba(0,0,0,0.3);" />
            <div class="tags">
                <span class="tag neuroscience">Neuroscience</span>
                <span class="tag ai">AI</span>
            </div>
        </div>

        <div class="project">
            <h3><a href="research/interpretable-features.html">Interpretable features to identify neural representations</a></h3>
            <h4>Making neural representations (natural or artificial) interpretable using meta-space analysis</h4>
            <img src="assets/gifs/MSA_preview.png" alt="MSA interpretable features preview" style="width:100%;max-width:800px;display:block;margin:20px auto 0 auto;border-radius:8px;box-shadow:0 2px 8px rgba(0,0,0,0.3);" />
            <div class="tags">
                <span class="tag neuroscience">Neuroscience</span>
                <span class="tag ai">AI</span>
            </div>
        </div>

        <div class="project">
            <h3><a href="research/temporal-attention.html">Experiments on Humans and non-human primates: Temporal Attention and object recognition abilities</a></h3>
            <h4>Understanding how the brain uses temporal patterns to anticipate and shape perception</h4>
            <!-- <p>In this work, I investigate how the human brain extracts sub-second temporal patterns from repeated or structured contexts to anticipate upcoming stimuli. Combining EEG, psychophysical tasks, and continuous flash suppression paradigms, I examine how alpha oscillations and cortical excitability are shaped by learned temporal associations. These experiments reveal how predictive signals can enhance or suppress conscious perception, offering new insights into the fundamental role of time-based cues in shaping attention and perceptual thresholds.</p> -->
            <img src="assets/gifs/JNP2017.jpeg" alt="Temporal Attention EEG Results" style="width:100%;max-width:400px;display:block;margin:20px auto 0 auto;border-radius:8px;box-shadow:0 2px 8px rgba(0,0,0,0.3);" />
            <div class="tags">
                <span class="tag neuroscience">Neuroscience</span>
            </div>
        </div>
    </section>
    
    <section id="publications" class="publications">
        <h2>Journals, Proceedings, and Preprints</h2>
        
        <div class="publication">
            <p class="title"><a href="https://www.biorxiv.org/content/early/2025/10/23/2025.10.21.683535" target="_blank">Generative inference unifies feedback processing for learning and perception in natural and artificial vision</a></p>
            <p class="authors">Toosi, T., & Miller, K. D.</p>
            <p class="venue">bioRxiv (2025)</p>
        </div>
        
        <div class="publication">
            <p class="title"><a href="https://www.biorxiv.org/content/early/2025/10/29/2025.10.29.685363" target="_blank">Natural scene coding consistency in genetically-defined cell populations</a></p>
            <p class="authors">Toosi, T., & Miller, K. D.</p>
            <p class="venue">bioRxiv (2025)</p>
        </div>
        
        <div class="publication">
            <p class="title"><a href="https://openreview.net/forum?id=vL28JhJDEM" target="_blank">Interpretability at the Network Level: Prior-Guided Drift Diffusion for neural circuit analysis</a></p>
            <p class="authors">Toosi, T., & Miller, K. D.</p>
            <p class="venue">Mechanistic Interpretability Workshop, Neural Information Processing Systems (NeurIPS) (2025)</p>
        </div>
        
        <div class="publication">
            <p class="title"><a href="https://openreview.net/forum?id=SKXsct2WB2" target="_blank">Illusions as features: the generative side of recognition</a></p>
            <p class="authors">Toosi, T., & Miller, K. D.</p>
            <p class="venue">Workshop on Scientific Methods for Understanding Deep Learning, Advances in Neural Information Processing Systems (NeurIPS) (2024)</p>
        </div>
        
        <div class="publication">
            <p class="title"><a href="https://pmc.ncbi.nlm.nih.gov/articles/PMC11567678/" target="_blank">Brain-like flexible visual inference by harnessing feedback-feedforward alignment</a></p>
            <p class="authors">Toosi, T., & Issa, E. B.</p>
            <p class="venue">Advances in Neural Information Processing Systems (NeurIPS) (2023)</p>
        </div>
        
        <div class="publication">
            <p class="title"><a href="https://arxiv.org/abs/2312.08545" target="_blank">Representational constraints underlying similarity between task-optimized neural systems</a></p>
            <p class="authors">Toosi, T.</p>
            <p class="venue">UniReps Workshop, Advances in Neural Information Processing Systems (NeurIPS) (2023)</p>
        </div>
        
        <div class="publication">
            <p class="title"><a href="https://openreview.net/forum?id=mCmerkTCG2S" target="_blank">Brain-like temporal straightening of natural movies in robust feedforward neural networks</a></p>
            <p class="authors">Toosi, T., & Issa, E. B.</p>
            <p class="venue">International Conference on Learning Representations (ICLR) (2023)</p>
        </div>
        
        <div class="publication">
            <p class="title"><a href="https://www.sciencedirect.com/science/article/pii/S2589004222020612" target="_blank">Marmoset core visual object recognition behavior is comparable to that of macaques and humans</a></p>
            <p class="authors">Kell, A. J. E., Bokor, S., Jeon, Y., Toosi, T., & Issa, E. B.</p>
            <p class="venue">iScience (2023)</p>
        </div>
        
        <div class="publication">
            <p class="title"><a href="https://journals.physiology.org/doi/full/10.1152/jn.00969.2016" target="_blank">Learning temporal context enhances the prestimulus alpha oscillations in the parietal cortex and improves the visual discrimination performance</a></p>
            <p class="authors">Toosi, T., Tousi, E. K., & Esteky, H.</p>
            <p class="venue">Journal of Neurophysiology (2016)</p>
        </div>
        
        <h2>Recent Peer Reviewed Abstracts</h2>
        
        <div class="publication">
            <p class="title">Unifying Gestalt Principles Through Inference-Time Prior Integration</p>
            <p class="authors">Toosi, T., & Miller, K. D.</p>
            <p class="venue">Interpreting Cognition in Deep Learning Models Workshop, Neural Information Processing Systems (NeurIPS) (2025)</p>
        </div>
        
        <div class="publication">
            <p class="title">A unified computational framework for visual dysfunctions in psychosis</p>
            <p class="authors">Toosi, T., & Miller, K. D.</p>
            <p class="venue">Vision Science Society (2025)</p>
        </div>
        
        <div class="publication">
            <p class="title">Generative inference in object recognition models—A unifying framework for discriminative and generative computations in vision</p>
            <p class="authors">Toosi, T., & Miller, K. D.</p>
            <p class="venue">From Neuroscience to Artificially Intelligent Systems (2024)</p>
        </div>
        
        <div class="publication">
            <p class="title">Generative perceptual inference in deep neural network models of object recognition induces illusory contours and shapes</p>
            <p class="authors">Toosi, T., & Miller, K. D.</p>
            <p class="venue">Cognitive Computational Neuroscience (CCN) (2024)</p>
        </div>
        
        <div class="publication">
            <p class="title">Emergence of illusory contours in robust deep neural networks by accumulation of implicit priors</p>
            <p class="authors">Toosi, T., & Miller, K. D.</p>
            <p class="venue">Computational and Systems Neuroscience (CoSyNe) (2024)</p>
        </div>
        
        <div class="publication">
            <p class="title">Object-enhanced and object-centered representations across primate ventral visual cortex</p>
            <p class="authors">Toosi, T., Kriegeskorte, N., & Issa, E. B.</p>
            <p class="venue">Cognitive Computational Neuroscience (CCN) (2023)</p>
        </div>
        
        <div class="publication">
            <p class="title">Perceptually-aligned gradients by sampling the implicit prior</p>
            <p class="authors">Toosi, T.</p>
            <p class="venue">Conference on the Mathematical Theory of Deep Neural Networks (DeepMath) (2022)</p>
        </div>
    </section>

    <section id="talks" class="talks">
        <h2>Invited Talks</h2>
        
        <div class="publication">
            <p class="title">A Unified Computational Framework for Perceptual Aberrations in Schizophrenia</p>
            <p class="venue">Horga Lab, New York State Psychiatric Institute (2025)</p>
        </div>

        <div class="publication">
            <p class="title">Intrinsic alignment to natural intelligence by integrating learned priors</p>
            <p class="venue">Gatsby Tri-Center Annual Meeting, University College London (2025)</p>
        </div>

        <div class="publication">
            <p class="title">Generative inference in object recognition models—A unifying framework for discriminative and generative computations in vision</p>
            <p class="venue">Johns Hopkins Kavli Neuroscience Discovery Institute, Baltimore (2025)<br>Visual Inference Lab, Columbia University (2025)<br>TigerBrain Research Symposium, Princeton University (2024)<br>From Neuroscience to Artificially Intelligent Systems, Cold Spring Harbor Laboratory (2024)</p>
        </div>

        <div class="publication">
            <p class="title">Generative perceptual inference in deep neural network models of object recognition induces illusory shapes</p>
            <p class="venue">Swartz Foundation Meeting, University of Washington (2024)</p>
        </div>

        <div class="publication">
            <p class="title">Emergence of illusory contours in robust deep neural networks by accumulation of implicit priors</p>
            <p class="venue">Object Recognition: Models, Vision Science Society Meeting, St. Pete Beach Florida (2024)</p>
        </div>

        <div class="publication">
            <p class="title">Cortical computations underlying the integration of perceptual priors and sensory processing</p>
            <p class="venue">Brain Science External Postdoc Seminar Series, Brown University (2024)</p>
        </div>

        <div class="publication">
            <p class="title">Can images predict neural patterns better than Deep Nets?</p>
            <p class="venue">ICBINB Workshop, Cosyne Meeting, Lisbon, Portugal (2024)</p>
        </div>

        <div class="publication">
            <p class="title">Harnessing feedback pathways: Integrating perceptual priors in sensory processing</p>
            <p class="venue">SYNAPSES Seminar Series, Yale University (2024)</p>
        </div>

        <div class="publication">
            <p class="title">Uncovering the evolution of neural representations in the ventral visual stream</p>
            <p class="venue">Neuroscience and Artificial Intelligence Laboratory (NeuroAILab), Stanford University (2023)</p>
        </div>

        <div class="publication">
            <p class="title">Interpretable intermediate representations in primate ventral visual cortex</p>
            <p class="venue">Visual Inference Lab, Columbia University (2023)</p>
        </div>

        <div class="publication">
            <p class="title">Representational straightening of natural movies in robust feedforward neural networks</p>
            <p class="venue">Visual Object and Scene Recognition Nanosymposium, Society for Neuroscience Meeting, San Diego (2022)</p>
        </div>

        <div class="publication">
            <p class="title">Symbiotic learning of feedforward and feedback networks</p>
            <p class="venue">From Neuroscience to Artificially Intelligent Systems, Cold Spring Harbor Laboratory (2020)</p>
        </div>
    </section>
    <script>
        // Visitor counter for all visitors
        async function updateCounter() {
            try {
                // Get current count
                const getResponse = await fetch('https://api.countapi.xyz/get/toosi.github.io/visits');
                const getData = await getResponse.json();
                
                // Update count
                const updateResponse = await fetch('https://api.countapi.xyz/hit/toosi.github.io/visits');
                const updateData = await updateResponse.json();
                
                // Create or update counter display
                let counterDisplay = document.getElementById('visitor-counter');
                if (!counterDisplay) {
                    counterDisplay = document.createElement('div');
                    counterDisplay.id = 'visitor-counter';
                    counterDisplay.style.position = 'fixed';
                    counterDisplay.style.bottom = '20px';
                    counterDisplay.style.right = '20px';
                    counterDisplay.style.backgroundColor = 'rgba(255,255,255,0.9)';
                    counterDisplay.style.color = '#006699';
                    counterDisplay.style.border = '1px solid #e0e0e0';
                    counterDisplay.style.padding = '8px 15px';
                    counterDisplay.style.borderRadius = '8px';
                    counterDisplay.style.fontSize = '14px';
                    counterDisplay.style.zIndex = '1000';
                    counterDisplay.style.fontFamily = "'Open Sans', Verdana, sans-serif";
                    counterDisplay.style.boxShadow = '0 2px 4px rgba(0,0,0,0.2)';
                    document.body.appendChild(counterDisplay);
                }
                counterDisplay.textContent = `Total Visits: ${updateData.value}`;
            } catch (error) {
                console.log('Counter error:', error);
            }
        }

        // Initialize counter when the page loads
        document.addEventListener('DOMContentLoaded', updateCounter);

        // Show/hide fixed name based on scroll position (desktop only)
        function handleScroll() {
            const fixedName = document.getElementById('fixedName');
            if (fixedName && window.innerWidth >= 769) {
                if (window.scrollY > 200) {
                    fixedName.style.display = 'block';
                } else {
                    fixedName.style.display = 'none';
                }
            }
        }

        // Add scroll event listener
        window.addEventListener('scroll', handleScroll);
        window.addEventListener('resize', handleScroll);
        
        // Initialize on load
        document.addEventListener('DOMContentLoaded', handleScroll);
    </script>
</body>
</html>