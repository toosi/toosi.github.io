<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Tahereh Toosi - Academic Website</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            line-height: 1.6;
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
            color: #333;
        }
        header {
            display: flex;
            align-items: center;
            margin-bottom: 30px;
        }
        .profile-img {
            width: 200px;
            border-radius: 50%;
            margin-right: 30px;
            box-shadow: 0 4px 8px rgba(0,0,0,0.1);
        }
        .header-content {
            flex: 1;
        }
        h1 {
            margin-bottom: 10px;
            color: #1a73e8;
        }
        .projects {
            margin-top: 40px;
        }
        .project {
            margin-bottom: 30px;
            padding: 20px;
            border-radius: 8px;
            background-color: #f8f9fa;
            box-shadow: 0 2px 4px rgba(0,0,0,0.05);
        }
        .project h3 {
            color: #1a73e8;
            margin-top: 0;
        }
        .publications {
            margin-top: 40px;
        }
        .publication {
            margin-bottom: 20px;
            border-left: 3px solid #4285f4;
            padding-left: 15px;
        }
        .publication p {
            margin: 5px 0;
        }
        .publication .title {
            font-weight: bold;
        }
        .publication .authors {
            font-style: italic;
        }
        .publication .venue {
            color: #666;
        }
        .publications h3 {
            margin-top: 30px;
            margin-bottom: 15px;
            color: #1a73e8;
            border-bottom: 1px solid #e8f0fe;
            padding-bottom: 5px;
        }
        .nav {
            display: flex;
            justify-content: center;
            margin: 30px 0;
            gap: 20px;
        }
        .nav a {
            padding: 10px 20px;
            background-color: #f8f9fa;
            color: #1a73e8;
            text-decoration: none;
            border-radius: 4px;
            transition: background-color 0.3s;
        }
        .nav a:hover, .nav a.active {
            background-color: #e8f0fe;
        }
        .section {
            display: none;
        }
        .section.active {
            display: block;
        }
        .social-icons {
            display: flex;
            margin-top: 15px;
            gap: 15px;
        }
        .social-icon {
            width: 24px;
            height: 24px;
        }
        .social-icon svg {
            width: 100%;
            height: 100%;
            fill: #4285f4;
            transition: fill 0.3s;
        }
        .social-icon:hover svg {
            fill: #3367d6;
        }
    </style>
</head>
<body>
    <header>
        <img src="assets/profile_400x400-.png" alt="Tahereh Toosi" class="profile-img">
        <div class="header-content">
            <h1>Tahereh Toosi</h1>
            <p>
                Associate Research Scientist at Center for Theoretical Neuroscience, Columbia University. My research investigates the neural computations that drive perception by combining experimental techniques with methods from artificial intelligence and neuroscience. I merge theoretical insights with practical AI developments to enhance our understanding of both biological and machine vision systems, supported by NIH K99-R00.
            </p>
            <div class="social-icons">
                <a href="https://twitter.com/taherehtoosi" target="_blank" class="social-icon" title="Twitter">
                    <svg role="img" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M18.901 1.153h3.68l-8.04 9.19L24 22.846h-7.406l-5.8-7.584-6.638 7.584H.474l8.6-9.83L0 1.154h7.594l5.243 6.932ZM17.61 20.644h2.039L6.486 3.24H4.298Z"/></svg>
                </a>
                <a href="https://bsky.app/profile/taherehtoosi.bsky.social" target="_blank" class="social-icon" title="Bluesky">
                    <svg role="img" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M12 0C5.3723 0 0 5.3723 0 12s5.3723 12 12 12 12-5.3723 12-12S18.6277 0 12 0zm3.7416 16.0004c-.113.0748-.3107.1687-.6107.2527-1.0766.284-2.3818.4366-3.1309.4366-.749 0-2.0542-.1526-3.1308-.4379-.3001-.0827-.4978-.1766-.6108-.2527a.1466.1466 0 0 1-.0628-.12v-2.3543a.1401.1401 0 0 1 .086-.131c.344-.1508.6587-.3297.9668-.5326-.1868-.125-.3616-.24-.527-.3466-1.3054-1.0752-1.9804-2.6215-1.9804-3.3946 0-.9401.6337-2.1857 1.5664-3.041C9.2111 5.327 10.3607 4.8312 12 4.8312c1.6393 0 2.7889.4958 3.6914 1.3477.9327.8553 1.5664 2.1009 1.5664 3.041 0 .7731-.675 2.3194-1.9804 3.3946-.1654.1066-.3402.2216-.527.3466.3055.203.6228.3819.9668.5326.052.02.086.0734.086.131v2.3542c0 .048-.0229.0934-.0628.12z"/></svg>
                </a>
                <a href="https://www.linkedin.com/in/tahereh-toosi-45b99014/" target="_blank" class="social-icon" title="LinkedIn">
                    <svg role="img" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M20.447 20.452h-3.554v-5.569c0-1.328-.027-3.037-1.852-3.037-1.853 0-2.136 1.445-2.136 2.939v5.667H9.351V9h3.414v1.561h.046c.477-.9 1.637-1.85 3.37-1.85 3.601 0 4.267 2.37 4.267 5.455v6.286zM5.337 7.433c-1.144 0-2.063-.926-2.063-2.065 0-1.138.92-2.063 2.063-2.063 1.14 0 2.064.925 2.064 2.063 0 1.139-.925 2.065-2.064 2.065zm1.782 13.019H3.555V9h3.564v11.452zM22.225 0H1.771C.792 0 0 .774 0 1.729v20.542C0 23.227.792 24 1.771 24h20.451C23.2 24 24 23.227 24 22.271V1.729C24 .774 23.2 0 22.222 0h.003z"/></svg>
                </a>
                <a href="mailto:tahereh.toosi@columbia.edu" class="social-icon" title="Email">
                    <svg role="img" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M24 5.457v13.909c0 .904-.732 1.636-1.636 1.636h-3.819V11.73L12 16.64l-6.545-4.91v9.273H1.636A1.636 1.636 0 0 1 0 19.366V5.457c0-2.023 2.309-3.178 3.927-1.964L5.455 4.64 12 9.548l6.545-4.91 1.528-1.145C21.69 2.28 24 3.434 24 5.457z"/></svg>
                </a>
                <a href="assets/Tahereh_CV_2025_norefs.pdf" target="_blank" class="social-icon" title="CV">
                    <img src="assets/icons/CV.png" alt="CV" style="width: 24px; height: 24px;">
                </a>
            </div>
        </div>
    </header>

    <nav class="nav">
        <a href="#projects" class="active" onclick="showSection('projects')">Projects</a>
        <a href="#publications" onclick="showSection('publications')">Publications</a>
    </nav>

    <section id="projects" class="projects section active">
        <h2>Selected Projects</h2>
        <div class="project">
            <h3>Generative Inference: A Neural Framework for Perceptual Completion and Imagination</h3>
            <p>This project proposes a biologically inspired computational model in which cortical feedback performs a dual function: refining neural activations during learning and dynamically generating percepts during inference. The framework posits that feedback pathways, beyond correcting errors, guide neural activity toward statistically likely interpretations based on prior experience. This dual functionality explains classical visual illusions such as Kanizsa figures and the Rubin face-vase effect, as well as Gestalt phenomena of perceptual organization. Moreover, the model extends to scenarios where sensory input is minimal or absent, offering a computational basis for imagination and hallucination. By bridging the gap between artificial neural networks and biological vision, Generative Inference paves the way for new insights into both human perception and adaptive machine learning strategies.</p>
        </div>
        
        <div class="project">
            <h3>Feedback Feedforward Alignment</h3>
            <p>In this project, we explore the alignment between feedback and feedforward pathways in neural networks, investigating how this alignment contributes to efficient learning and robust perception. Our findings suggest that when these pathways are properly coordinated, networks demonstrate enhanced performance, faster convergence, and greater resilience to noisy inputs.</p>
        </div>
        
        <div class="project">
            <h3>Emergence of Straightened Representations in Robust Neural Networks</h3>
            <p>In this project, we explore how robust training techniques foster the emergence of straightened feature representations in feedforward neural networks when processing natural movie sequences. By leveraging adversarial robustness and random smoothing, our models exhibit a notable decrease in curvature within their latent spacesâ€”allowing for linear interpolation of temporal frames and reliable frame reconstruction. These straightened representations align with perceptual phenomena observed in human vision and demonstrate improved predictivity of neural activity in primary visual cortex (V1). Our results suggest that noise robustness can serve as a parsimonious and biologically plausible mechanism for generating temporal predictability in visual representations.</p>
        </div>
    </section>
    
    <section id="publications" class="publications section">
        <h2>Publications</h2>
        
        <h3>Journals, Proceedings, and Preprints</h3>
        
        <div class="publication">
            <p class="title">Illusions as features: the generative side of recognition</p>
            <p class="authors">Toosi, T., & Miller, K. D.</p>
            <p class="venue">Workshop on Scientific Methods for Understanding Deep Learning, Advances in Neural Information Processing Systems (NeurIPS) (2024)</p>
        </div>
        
        <div class="publication">
            <p class="title">Brain-like flexible visual inference by harnessing feedback-feedforward alignment</p>
            <p class="authors">Toosi, T., & Issa, E. B.</p>
            <p class="venue">Advances in Neural Information Processing Systems (NeurIPS) (2023)</p>
        </div>
        
        <div class="publication">
            <p class="title">Brain-like temporal straightening of natural movies in robust feedforward neural networks</p>
            <p class="authors">Toosi, T., & Issa, E. B.</p>
            <p class="venue">International Conference on Learning Representations (ICLR) (2023)</p>
        </div>
        
        <div class="publication">
            <p class="title">Representational constraints underlying similarity between task-optimized neural systems</p>
            <p class="authors">Toosi, T.</p>
            <p class="venue">arXiv (2023)</p>
        </div>
        
        <div class="publication">
            <p class="title">Marmoset core visual object recognition behavior is comparable to that of macaques and humans</p>
            <p class="authors">Kell, A. J. E., Bokor, S., Jeon, Y., Toosi, T., & Issa, E. B.</p>
            <p class="venue">iScience (2023)</p>
        </div>
        
        <div class="publication">
            <p class="title">Learning temporal context enhances the prestimulus alpha oscillations in the parietal cortex and improves the visual discrimination performance</p>
            <p class="authors">Toosi, T., Tousi, E. K., & Esteky, H.</p>
            <p class="venue">Journal of Neurophysiology (2016)</p>
        </div>
        
        <h3>Recent Peer Reviewed Abstracts</h3>
        
        <div class="publication">
            <p class="title">A unified computational framework for visual dysfunctions in psychosis</p>
            <p class="authors">Toosi, T., & Miller, K. D.</p>
            <p class="venue">Journal of Vision (2025)</p>
        </div>
        
        <div class="publication">
            <p class="title">Generative inference in object recognition modelsâ€”A unifying framework for discriminative and generative computations in vision</p>
            <p class="authors">Toosi, T., & Miller, K. D.</p>
            <p class="venue">From Neuroscience to Artificially Intelligent Systems (2024)</p>
        </div>
        
        <div class="publication">
            <p class="title">Generative perceptual inference in deep neural network models of object recognition induces illusory contours and shapes</p>
            <p class="authors">Toosi, T., & Miller, K. D.</p>
            <p class="venue">Cognitive Computational Neuroscience (CCN) (2024)</p>
        </div>
        
        <div class="publication">
            <p class="title">Emergence of illusory contours in robust deep neural networks by accumulation of implicit priors</p>
            <p class="authors">Toosi, T., & Miller, K. D.</p>
            <p class="venue">Computational and Systems Neuroscience (Cosyne) (2024)</p>
        </div>
        
        <div class="publication">
            <p class="title">Representational constraints underlying similarity between task-optimized neural systems</p>
            <p class="authors">Toosi, T.</p>
            <p class="venue">Unifying Representations in Neural Models Workshop, Neural Information Processing Systems (NeurIPS) (2023)</p>
        </div>
        
        <div class="publication">
            <p class="title">Object-enhanced and object-centered representations across primate ventral visual cortex</p>
            <p class="authors">Toosi, T., Kriegeskorte, N., & Issa, E. B.</p>
            <p class="venue">Cognitive Computational Neuroscience (CCN) (2023)</p>
        </div>
        
        <div class="publication">
            <p class="title">Perceptually-aligned gradients by sampling the implicit prior</p>
            <p class="authors">Toosi, T.</p>
            <p class="venue">Conference on the Mathematical Theory of Deep Neural Networks (DeepMath) (2022)</p>
        </div>
    </section>
    <script>
        function showSection(sectionId) {
            // Hide all sections
            document.querySelectorAll('.section').forEach(function(section) {
                section.classList.remove('active');
            });
            
            // Show the selected section
            document.getElementById(sectionId).classList.add('active');
            
            // Update active nav item
            document.querySelectorAll('.nav a').forEach(function(navItem) {
                navItem.classList.remove('active');
                if (navItem.getAttribute('href') === '#' + sectionId) {
                    navItem.classList.add('active');
                }
            });
        }
    </script>
</body>
</html>